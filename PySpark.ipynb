{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNawFykQ9zgsbHzlscxwNWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDAyesha/PySpark/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark is an interface for Apache Spark in Python is often used for large scale data processing and machine learning.\n",
        "\n",
        "PySpark is a library(Spark API)\n",
        "\n",
        "If we have large amount og data like 128gb we use distributed systems(multiple systems) to run the processes\n",
        "we can use Spark with other programming languages like Java, Scala, R, SQL, Python\n",
        "\n",
        "Spark Emblem helps us to perform ML task, regression, classification, clustering\n",
        "Advantages of Apache Spark:\n",
        "Speed: Run workloads 100x faster (faster than MapReduce)\n",
        "Ease of Use:write applications quickly (stack of libraries)\n",
        "Generality: Combine SQL, streaming and complex analytics\n",
        "Runs Everywhere (on Hadoop,Apache Mesos, Kubernetes, standalone, cloud. can access diverse data sources)\n",
        "\n",
        "OVERVIEW:\n",
        "Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python, and R, and\n",
        "an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and\n",
        "structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and\n",
        "Structured Streaming for incremental computation and stream processing."
      ],
      "metadata": {
        "id": "RINEWMKNlUiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocjwn8EFlDf-",
        "outputId": "6b8a77cb-b7b1-470f-ae64-b422af866649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=3c3429137b7910df5ce73e08d60aa80fc3d7069694a3dc105fc6b2ae4c3ae1f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark"
      ],
      "metadata": {
        "id": "m20iYOlJlFhT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f1=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "X8Qmfzu8l2Kr",
        "outputId": "06d8ea85-364f-43ee-b9a9-40b36453a579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ddb06cfd-4b5f-49cb-bb09-bbaea0ada1fd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ddb06cfd-4b5f-49cb-bb09-bbaea0ada1fd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book1.csv to Book1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "type(pd.read_csv('Book1.csv')) #pandas dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN8k1LxNm_F8",
        "outputId": "3473d302-0bc8-4d18-c120-4920a17bd173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "UB5JB2mInPCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "swdsLRQinTGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0EHZ9f1kng14",
        "outputId": "63e54720-639d-4399-95ad-4fb67dfdc82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f0a2bad70d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://17237741d2ed:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pyspark=spark.read.csv('Book1.csv')"
      ],
      "metadata": {
        "id": "NHQ89FuVnlPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pyspark\n",
        "#its taking A B as default column so it returns string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77-e9SfMn8qD",
        "outputId": "d343767e-bf89-4077-aa70-9d5dc0ce2937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxESPbf_oAcY",
        "outputId": "3c28c314-3e7d-4c3f-90e2-241a24e914a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|   _c0|_c1|\n",
            "+------+---+\n",
            "|  Name|Age|\n",
            "|Ayesha| 20|\n",
            "|  Sita| 18|\n",
            "|  Raji| 24|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To make Name and age as main column\n",
        "df_pyspark = spark.read.option('header','true').csv('Book1.csv').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkvHh1XMoSjT",
        "outputId": "af0edae6-dc9e-4c74-e856-740ce0092cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  Name|Age|\n",
            "+------+---+\n",
            "|Ayesha| 20|\n",
            "|  Sita| 18|\n",
            "|  Raji| 24|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)\n",
        "#sql dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbj_a16voqQx",
        "outputId": "6c1402b5-c435-4951-8784-874de9b3cd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(4)\n",
        "#we get it in list format whereas in pandas we get it in dataframe format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbRQywyGpAk0",
        "outputId": "80371fca-1e5c-4f0b-8a3f-a024105df478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_c0='Name', _c1='Age'),\n",
              " Row(_c0='Ayesha', _c1='20'),\n",
              " Row(_c0='Sita', _c1='18'),\n",
              " Row(_c0='Raji', _c1='24')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema() #information about columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GlPD9XfpXcY",
        "outputId": "51a8b548-55eb-454e-a8f8-f8a627772966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PYSPARK DATAFRAME"
      ],
      "metadata": {
        "id": "e43MCtqJqC4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "mR0i8Xjoplen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "Rf9fjORDwGgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "QRU6eZB8wSw8",
        "outputId": "26a0d21e-f985-4052-fa1d-5432015832aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f0a2bad70d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://17237741d2ed:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##read dataset\n",
        "from google.colab import files\n",
        "f2=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_Qe26Xp2wUsR",
        "outputId": "930ee7de-fd2a-4eee-c0a4-b4091db3cc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1fffdf7d-48c5-4e33-907b-22d46a97c793\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1fffdf7d-48c5-4e33-907b-22d46a97c793\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book2.csv to Book2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#METHOD 1:\n",
        "df_pyspark=spark.read.option('header','true').csv('Book2.csv', inferSchema=True)\n",
        "#inferSchema helps to show the values as integer not as string in case of age and experience"
      ],
      "metadata": {
        "id": "5KRN4ioCwjxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check datatypes of column - printSchema is used\n",
        "df_pyspark.printSchema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl0wBeWbw6xw",
        "outputId": "5bd2976d-5164-4232-f917-b00e54477b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.printSchema of DataFrame[Name: string, Age: int, Experience: int]>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#METHOD 2:\n",
        "df_pyspark=spark.read.csv('Book2.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j_1X3OAxM-m",
        "outputId": "cd3e62f3-4d7c-429c-b537-ff6545984ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+\n",
            "|  Name|Age|Experience|\n",
            "+------+---+----------+\n",
            "|Ayesha| 20|         6|\n",
            "|  Sita| 18|         8|\n",
            "|  Raji| 24|         4|\n",
            "+------+---+----------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)\n",
        "#dataframe is a data structure inside which we can perform various operations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-TtXdQjxxy0",
        "outputId": "2dfc6c7b-02a9-4999-e2da-e1f1980b19c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to get columns names\n",
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QOi5KLsyIcD",
        "outputId": "6ae500dd-0b7a-44ca-f79c-0806cc7ce399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select a column\n",
        "col1 = df_pyspark.select('Name')"
      ],
      "metadata": {
        "id": "_cNn1oqazKfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUDMFVD3zpEm",
        "outputId": "7dbbef2d-1341-44de-c338-748bbf470097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|  Name|\n",
            "+------+\n",
            "|Ayesha|\n",
            "|  Sita|\n",
            "|  Raji|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(col1) #dataframe.dataframe not pandas.dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShhitQJUzvsq",
        "outputId": "4f59d6e5-976e-4836-8c3f-5746481bb9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select(['Name','Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qc6WAUrz0QH",
        "outputId": "e504cf76-adea-438d-b4ba-da5cde1caab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+\n",
            "|  Name|Experience|\n",
            "+------+----------+\n",
            "|Ayesha|         6|\n",
            "|  Sita|         8|\n",
            "|  Raji|         4|\n",
            "+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark['Name']\n",
        "#directly picking then we have return type as column\n",
        "#no show() function it gives error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oQPro0T0PZE",
        "outputId": "e0a030b0-9cb7-4cc9-ad3e-596aa9a24e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check data types\n",
        "df_pyspark.dtypes #same as pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6njavDv0xWP",
        "outputId": "f194bc7a-f615-42aa-aa11-2dc1b85c0943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()\n",
        "#returns a dataframe\n",
        "#min and max taken on index here it does count, mean,...on string also"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZqLpNkK1Fm6",
        "outputId": "5b3bad47-0064-4bd1-e2e6-9d65faed4fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+----------+\n",
            "|summary|  Name|               Age|Experience|\n",
            "+-------+------+------------------+----------+\n",
            "|  count|     3|                 3|         3|\n",
            "|   mean|  null|20.666666666666668|       6.0|\n",
            "| stddev|  null| 3.055050463303893|       2.0|\n",
            "|    min|Ayesha|                18|         4|\n",
            "|    max|  Sita|                24|         8|\n",
            "+-------+------+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add columns in dataframe\n",
        "#withColumn(colName, col) returns a new dataframe by adding a column or replacing the existing column that has same name\n",
        "addCol = df_pyspark.withColumn('Experience After 2 yrs', df_pyspark['Experience']+2)"
      ],
      "metadata": {
        "id": "e_APEioa1SAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "addCol.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zci_1gId2z10",
        "outputId": "af879c56-150d-4217-e3bb-b983750e1714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+----------------------+\n",
            "|  Name|Age|Experience|Experience After 2 yrs|\n",
            "+------+---+----------+----------------------+\n",
            "|Ayesha| 20|         6|                     8|\n",
            "|  Sita| 18|         8|                    10|\n",
            "|  Raji| 24|         4|                     6|\n",
            "+------+---+----------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns in dataframe\n",
        "#drop() function by default takes column names :list or single column.\n",
        "#this is not an inplace operation, so we need to assign it to a variable to use it\n",
        "df_pyspark.drop('Experience After 2 yrs').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-8OfNls26Yp",
        "outputId": "c1ca61bd-9621-4e6e-fdf0-cb4c15dd4093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+\n",
            "|  Name|Age|Experience|\n",
            "+------+---+----------+\n",
            "|Ayesha| 20|         6|\n",
            "|  Sita| 18|         8|\n",
            "|  Raji| 24|         4|\n",
            "+------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rename the column\n",
        "#withColumnRenamed(existing, new)\n",
        "df_pyspark.withColumnRenamed('Name','New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EcWsPzI3j5-",
        "outputId": "67e44671-509c-4ff3-a212-f2dbfac4677d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+----------+\n",
            "|New Name|Age|Experience|\n",
            "+--------+---+----------+\n",
            "|  Ayesha| 20|         6|\n",
            "|    Sita| 18|         8|\n",
            "|    Raji| 24|         4|\n",
            "+--------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLING MISSING VALUES"
      ],
      "metadata": {
        "id": "iPvzitQv4geW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "EjeqwALG4S4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f3=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "U0YpAQxK5UbG",
        "outputId": "7ee63e5f-b4bd-48ba-9280-5c27563b5e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-301e6fd9-9820-4482-9dee-16c4b144b707\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-301e6fd9-9820-4482-9dee-16c4b144b707\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book3.csv to Book3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('Book3.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "qZLYzfCx5-Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FejU-luM66wd",
        "outputId": "ecbefccd-c1e0-497b-d2f8-c2d3c5dc3c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+\n",
            "|  Name| Age|Experience|Salary|\n",
            "+------+----+----------+------+\n",
            "|Ayesha|  20|         6| 30000|\n",
            "|  Sita|  18|         8| 40000|\n",
            "|  Raji|  24|         4| 20000|\n",
            "|   Anu|  30|         5| 26000|\n",
            "| Priya|  29|         3| 25000|\n",
            "|  Asri|  23|         1| 32000|\n",
            "|Sweety|null|      null| 15000|\n",
            "|  null|  26|         2| 45000|\n",
            "|  null|  21|      null|  null|\n",
            "+------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the null values\n",
        "#drop(how='any',thresh=None,subset=None)\n",
        "#df_pyspark.na.drop().show()\n",
        "#all rows with null values will be deleted as by default how='any'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ4ElKSt6NmY",
        "outputId": "e6362243-3fc3-4d1f-96bb-e727f3d7fc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|  Raji| 24|         4| 20000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#any==how\n",
        "df_pyspark.na.drop(how='all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no8vgOLz6v_7",
        "outputId": "fad84a88-776f-46e6-8e56-1d02e8a40424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+\n",
            "|  Name| Age|Experience|Salary|\n",
            "+------+----+----------+------+\n",
            "|Ayesha|  20|         6| 30000|\n",
            "|  Sita|  18|         8| 40000|\n",
            "|  Raji|  24|         4| 20000|\n",
            "|   Anu|  30|         5| 26000|\n",
            "| Priya|  29|         3| 25000|\n",
            "|  Asri|  23|         1| 32000|\n",
            "|Sweety|null|      null| 15000|\n",
            "|  null|  26|         2| 45000|\n",
            "|  null|  21|      null|  null|\n",
            "+------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#threshold : specify atleast 2 non-null values are there\n",
        "df_pyspark.na.drop(how='all',thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMc0H4-77owN",
        "outputId": "481c162a-1d92-493b-e531-0c95c7b05ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+\n",
            "|  Name| Age|Experience|Salary|\n",
            "+------+----+----------+------+\n",
            "|Ayesha|  20|         6| 30000|\n",
            "|  Sita|  18|         8| 40000|\n",
            "|  Raji|  24|         4| 20000|\n",
            "|   Anu|  30|         5| 26000|\n",
            "| Priya|  29|         3| 25000|\n",
            "|  Asri|  23|         1| 32000|\n",
            "|Sweety|null|      null| 15000|\n",
            "|  null|  26|         2| 45000|\n",
            "+------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#subset: from a specific column that has Null values, the entire row is deleted\n",
        "df_pyspark.na.drop(how='all',subset=['Experience']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kitz0S9D8LJ0",
        "outputId": "3310945b-3810-415f-9b73-d7dd13667874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|  Raji| 24|         4| 20000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "|  null| 26|         2| 45000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fill the missing values\n",
        "#fill(value, subset) here subset is the column name\n",
        "df_pyspark.na.fill('missing',['Experience','Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l_udOOw8qmT",
        "outputId": "e2d0b0d3-954a-4c30-ea8b-d272768b6ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+\n",
            "|  Name| Age|Experience|Salary|\n",
            "+------+----+----------+------+\n",
            "|Ayesha|  20|         6| 30000|\n",
            "|  Sita|  18|         8| 40000|\n",
            "|  Raji|  24|         4| 20000|\n",
            "|   Anu|  30|         5| 26000|\n",
            "| Priya|  29|         3| 25000|\n",
            "|  Asri|  23|         1| 32000|\n",
            "|Sweety|null|      null| 15000|\n",
            "|  null|  26|         2| 45000|\n",
            "|  null|  21|      null|  null|\n",
            "+------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replace null values with mean using Imputer() function\n",
        "from pyspark.ml.feature import Imputer\n",
        "imputer = Imputer(\n",
        "    inputCols=['Age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Exprience','Salary']]\n",
        ").setStrategy(\"mean\") #mean/ median/ mode"
      ],
      "metadata": {
        "id": "9bjY1pzG9PTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzCHH5pYUrA9",
        "outputId": "092f60fc-bfd1-45ae-aff5-dbc4f9be44be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+-----------+-----------------+--------------+\n",
            "|  Name| Age|Experience|Salary|Age_imputed|Exprience_imputed|Salary_imputed|\n",
            "+------+----+----------+------+-----------+-----------------+--------------+\n",
            "|Ayesha|  20|         6| 30000|         20|                6|         30000|\n",
            "|  Sita|  18|         8| 40000|         18|                8|         40000|\n",
            "|  Raji|  24|         4| 20000|         24|                4|         20000|\n",
            "|   Anu|  30|         5| 26000|         30|                5|         26000|\n",
            "| Priya|  29|         3| 25000|         29|                3|         25000|\n",
            "|  Asri|  23|         1| 32000|         23|                1|         32000|\n",
            "|Sweety|null|      null| 15000|         23|                4|         15000|\n",
            "|  null|  26|         2| 45000|         26|                2|         45000|\n",
            "|  null|  21|      null|  null|         21|                4|         29125|\n",
            "+------+----+----------+------+-----------+-----------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILTER OPERATION\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ANF3MtIVtol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for retrieval of records we use filter like boolean conditions\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "iykOG_J5VbYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f4=files.upload()"
      ],
      "metadata": {
        "id": "EnYX9WjHWzqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('Book4.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR0sbzY7W7ZT",
        "outputId": "2f38cf77-a3c7-4063-9d61-3ed3ec71fcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|  Raji| 24|         4| 20000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter operations"
      ],
      "metadata": {
        "id": "KWRnoeEnXMCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#salary less than or equal to 20000\n",
        "#METHOD 1:\n",
        "df_pyspark.filter('Salary<=20000').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ_Enq5sX4T8",
        "outputId": "fd30ad17-0365-44de-fe34-76278391f50d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+------+\n",
            "|Name|Age|Experience|Salary|\n",
            "+----+---+----------+------+\n",
            "|Raji| 24|         4| 20000|\n",
            "+----+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.filter('Salary<=20000').select(['Name','Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFJjWtiiYHks",
        "outputId": "910febad-a084-48a7-eb15-5b6f55cb9ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "|Raji| 24|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#METHOD 2:\n",
        "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRWoGD5EYVSn",
        "outputId": "edb42858-1c3f-45fa-e4d0-0b2906a542a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+------+\n",
            "|Name|Age|Experience|Salary|\n",
            "+----+---+----------+------+\n",
            "|Raji| 24|         4| 20000|\n",
            "+----+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.filter((df_pyspark['Salary']<=20000) | #&\n",
        "                  (df_pyspark['Salary']>=15000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUG4emL4Ypzj",
        "outputId": "f15efa57-0d78-492d-c92a-89b5587f4aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|  Raji| 24|         4| 20000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inverse filter(NOT) operation\n",
        "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVieQt10ZFrv",
        "outputId": "cd1f6e1d-1358-409d-ca96-d08d11452c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUPBY & AGGREGATE FUNCTIONS\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KEYhmBegZkxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Agg').getOrCreate()"
      ],
      "metadata": {
        "id": "TRsz8CzjZZ8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "qyjllHPYa1AD",
        "outputId": "b06be7a1-8319-4993-a37b-183e86f5e5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8402c62770>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8e576c02293e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f5=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Hl4U-rKAa3CQ",
        "outputId": "d8c28b44-34f9-4a63-f287-ea07368d9be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7bb16aac-536c-400e-b5a9-0434e313372c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7bb16aac-536c-400e-b5a9-0434e313372c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book 5.csv to Book 5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv('Book 5.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "RETnpGmQa8x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC-D_hKabHuj",
        "outputId": "9b09663c-0ce1-46fa-be00-ec6ab0a8f6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+------+\n",
            "|  Name| Departments|Salary|\n",
            "+------+------------+------+\n",
            "|Ayesha|Data Science| 10000|\n",
            "|Ayesha|Data Science|  5000|\n",
            "|  Raji|    Big Data|  8000|\n",
            "|   Anu|         IOT| 12000|\n",
            "|Ayesha|Data Science| 10000|\n",
            "|  Raji|    Big Data|  6000|\n",
            "|Ayesha|Data Science|  4000|\n",
            "|   Anu|         IOT| 20000|\n",
            "|  Raji|    Big Data| 15000|\n",
            "|   Anu|         IOT| 18000|\n",
            "+------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmxB9J6jbKsn",
        "outputId": "8414040b-15fb-4307-eee7-e7aba75d9f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Departments: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GroupBy\n",
        "#Groupby and Aggregate work together that is first we apply groupby then aggregate function\n",
        "df_pyspark.groupby('Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EygMObFZbTrg",
        "outputId": "492c995c-5407-4d1d-933d-ef039839aded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.group.GroupedData at 0x7f84009341c0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find max salary among all employees\n",
        "df_pyspark.groupby('Name').sum()\n",
        "#we can't apply sum on string, only on int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVKOntZqbduz",
        "outputId": "3652db79-48ce-4e5f-b2d7-42586e62c151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, sum(Salary): bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grouped to find maximum salary\n",
        "df_pyspark.groupby('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xXyOvJpb0nj",
        "outputId": "eeb5dac1-2d1e-4682-bc21-fe5bef8eba2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|sum(Salary)|\n",
            "+------+-----------+\n",
            "|  Raji|      29000|\n",
            "|Ayesha|      29000|\n",
            "|   Anu|      50000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupby('Name').max().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TthCO_xHe0Kl",
        "outputId": "99d0bb79-3bdc-4c4f-8833-c831053c63cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|max(Salary)|\n",
            "+------+-----------+\n",
            "|  Raji|      15000|\n",
            "|Ayesha|      10000|\n",
            "|   Anu|      20000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupby('Name').min().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfX6NJYnfC9O",
        "outputId": "67fc42c8-0a55-4db9-9286-131c524cbcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|min(Salary)|\n",
            "+------+-----------+\n",
            "|  Raji|       6000|\n",
            "|Ayesha|       4000|\n",
            "|   Anu|      12000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupby('Name').avg().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DQfrpsMfOKc",
        "outputId": "35889fbb-e1b3-4934-baf5-70ac141d4ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|  Name|       avg(Salary)|\n",
            "+------+------------------+\n",
            "|  Raji| 9666.666666666666|\n",
            "|Ayesha|            7250.0|\n",
            "|   Anu|16666.666666666668|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#group by departments which gives maximum salary\n",
        "df_pyspark.groupby('Departments').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YKXpeihcDX-",
        "outputId": "92e5134b-9849-431d-97c6-bafcb806eebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|sum(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|      50000|\n",
            "|    Big Data|      29000|\n",
            "|Data Science|      29000|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.groupby('Name').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HUhghAFdqcB",
        "outputId": "97839967-e0b9-4d43-a95c-d276bf132cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|  Name|       avg(Salary)|\n",
            "+------+------------------+\n",
            "|  Raji| 9666.666666666666|\n",
            "|Ayesha|            7250.0|\n",
            "|   Anu|16666.666666666668|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many employees are working based on department\n",
        "df_pyspark.groupby('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvyAIsjreArZ",
        "outputId": "c76fef35-6923-4763-ccc8-d69c1dd8720c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    3|\n",
            "|    Big Data|    3|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#as key value pairs\n",
        "df_pyspark.agg({'Salary':'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfmh9qcOeWEY",
        "outputId": "b79bccea-d4a3-4669-8cc7-5489dcce828e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|     108000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of PySpark ML\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9Z1XVjVVg0wT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Spark ML, there are two different techniques: RDD & Dataframe APIs\n",
        "\n",
        "The building block of the Spark API is its RDD API. In the RDD API, there are two types of operations: transformations, which define a new dataset based on previous ones, and actions, which kick off a job to execute on a cluster.\n",
        "\n",
        "In Spark, a DataFrame is a distributed collection of data organized into named columns. Users can use DataFrame API to perform various relational operations on both external data sources and Spark’s built-in distributed collections without providing specific procedures for processing data."
      ],
      "metadata": {
        "id": "E8AApZ_Sfj77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#based on age and experience predict the salary of employee\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('ML').getOrCreate()"
      ],
      "metadata": {
        "id": "WsOtDHIseomk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "f4=files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FxjjHA0vs9ND",
        "outputId": "559db40c-cfb5-459d-bee5-6153e2c18ac2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6ffcd344-f3d3-4888-85c5-19457ddb3d46\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6ffcd344-f3d3-4888-85c5-19457ddb3d46\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book4.csv to Book4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read the dataset\n",
        "#linear regression example\n",
        "training=spark.read.csv('Book4.csv',header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "wj0kAAedhHNy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8EzpqTdhd_r",
        "outputId": "0884b520-2b1e-4ed7-d1b0-b20ea4afd3ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Ayesha| 20|         6| 30000|\n",
            "|  Sita| 18|         8| 40000|\n",
            "|  Raji| 24|         4| 20000|\n",
            "|   Anu| 30|         5| 26000|\n",
            "| Priya| 29|         3| 25000|\n",
            "|  Asri| 23|         1| 32000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Utrxo1nhl_k",
        "outputId": "4ee61010-a910-4c3a-a334-fd3f0b2445b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5msaSFuciGxE",
        "outputId": "f8ee226c-1937-4747-e021-f691db7bb9a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In pyspark we create way to group all my independent features : vector assembler(a module that convert numerical feature into single vector)\n",
        "#grouped columns will act as new feature(independent)\n",
        "#in case of categorical features convert them into numerical representation\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "featureassembler = VectorAssembler(inputCols=['Age','Experience'], outputCol='Independent Feature')"
      ],
      "metadata": {
        "id": "Ng_8jM_ziL-Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = featureassembler.transform(training)"
      ],
      "metadata": {
        "id": "HaZAd61Zuq6A"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtqBQZEju6Cr",
        "outputId": "ac58694b-cc73-4fe6-e5ce-b3d5cb45a115"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+-------------------+\n",
            "|  Name|Age|Experience|Salary|Independent Feature|\n",
            "+------+---+----------+------+-------------------+\n",
            "|Ayesha| 20|         6| 30000|         [20.0,6.0]|\n",
            "|  Sita| 18|         8| 40000|         [18.0,8.0]|\n",
            "|  Raji| 24|         4| 20000|         [24.0,4.0]|\n",
            "|   Anu| 30|         5| 26000|         [30.0,5.0]|\n",
            "| Priya| 29|         3| 25000|         [29.0,3.0]|\n",
            "|  Asri| 23|         1| 32000|         [23.0,1.0]|\n",
            "+------+---+----------+------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdR0Dwhsu7tR",
        "outputId": "214745b2-2f2b-41c1-d2f4-c6a4dc799081"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary', 'Independent Feature']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data = output.select(\"Independent Feature\", \"Salary\")"
      ],
      "metadata": {
        "id": "zFJo26Vpu_3C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKZ2kQf4vOkr",
        "outputId": "355791aa-8514-415a-f6b0-45e7bbe74ca1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+\n",
            "|Independent Feature|Salary|\n",
            "+-------------------+------+\n",
            "|         [20.0,6.0]| 30000|\n",
            "|         [18.0,8.0]| 40000|\n",
            "|         [24.0,4.0]| 20000|\n",
            "|         [30.0,5.0]| 26000|\n",
            "|         [29.0,3.0]| 25000|\n",
            "|         [23.0,1.0]| 32000|\n",
            "+-------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "#train_test_split\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "train_data, test_data=finalized_data.randomSplit([0.75,0.25])\n",
        "regressor=LinearRegression(featuresCol='Independent Feature', labelCol='Salary')\n",
        "regressor=regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "5KWnjIk4viA1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZp_Nr5_04ki",
        "outputId": "d4eb2e66-670c-4e6f-8eb5-771ccb9310eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([-1286.6766, -15.7186])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkKSpXyo09UF",
        "outputId": "bf742e40-6889-4a6f-bf30-e0fef73d963a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58805.389221555655"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "lSOVx31n1Bpa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-oVNw2W1HJV",
        "outputId": "315c7c35-924f-4c92-8501-c32760712f17"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+------------------+\n",
            "|Independent Feature|Salary|        prediction|\n",
            "+-------------------+------+------------------+\n",
            "|         [30.0,5.0]| 26000|20126.497005988378|\n",
            "+-------------------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVwNZEon1MaT",
        "outputId": "9e210915-8234-4de1-8c0e-f08e16339539"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5873.502994011622, 34498037.42066348)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#databricks is aplatform where you can actually work with pyspark and apache spark\n",
        "#s3 bucket: storage unit in aws\n",
        "#Databricks is a unified set of tools for building, deploying, sharing, and maintaining enterprise-grade data solutions at scale.\n",
        "#it supports AWS, GCP, Microsoft Azure\n",
        "#Amazon kinesis for live streaming data"
      ],
      "metadata": {
        "id": "YZNyQX_P1fGI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handling categorical features - String Indexer\n",
        "#StringIndexer(inputCol, outputCol, inputCols, outputCols, handleInvalid, stringOrderType)\n",
        "\n",
        "# consider an example of multiple regression with multiple features\n",
        "# from pyspark.ml.feature import StringIndexer #for ordinal encoding(0's & 1's)\n",
        "# indexer = StringIndexer(inputCol='sex',outputCol='sex_indexed')\n",
        "# df_r=indexer.fit(df).transform(df)\n",
        "# df_r.show()"
      ],
      "metadata": {
        "id": "mRgYbUFy8GNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexer = StringIndexer(inputCols=['smoker','day','time'],outputCols=['smoker_indexed', 'day_indexed', 'time_indexed']) # for multiple features\n",
        "# df_r=indexer.fit(df_r).transform(df_r)\n",
        "# df_r.show()"
      ],
      "metadata": {
        "id": "OsH5NKqG9dRK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# featureassembler = VectorAssembler(inputCols=['tip','size', 'sex_indexed','smoker_indexed', 'day_indexed', 'time_indexed'], outputCol='Independent Feature')\n",
        "# #should be in order of columns. These all are independent features that are to be grouped together\n",
        "# output=featureassembler.transform(df_r)"
      ],
      "metadata": {
        "id": "hJocTB74-KKH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output.select('Independent Feature').show()"
      ],
      "metadata": {
        "id": "qrITb5CY_gHr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total_bill is dependent feature\n",
        "# finalized_data=output.select('Independent Feature', 'total_bill')\n",
        "# finalized_data.show()"
      ],
      "metadata": {
        "id": "vihHWXh8_tuS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply linear regression\n",
        "# from pyspark.ml.regression import LinearRegression\n",
        "# train_data, test_data=finalized_data.randomSplit([0.75,0.25])\n",
        "# regressor=LinearRegression(featuresCol='Independent Feature', labelCol='total_bill')\n",
        "# regressor=regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "5zLbfxPDAEjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regressor.coefficients : based on no. of features\n",
        "# regressor.intercept"
      ],
      "metadata": {
        "id": "stnSambZAnG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "# pred_results= regressor.evaluate(test_data)\n",
        "\n",
        "# final comparison\n",
        "# pred_results.predictions.show() : to compare actual with predicted values"
      ],
      "metadata": {
        "id": "oCLwLd-BAxTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R2 performance metric\n",
        "# pred_results.r2"
      ],
      "metadata": {
        "id": "wU_zeuk0BKrZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}